---
title: "Individual size distributions in relation to bin size"
author: "Max Lindmark"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format: 
  html:
    page-layout: full
    embed-resources: true
knitr: 
  opts_chunk:
    fig.align: center
    out-width: 80%
editor: source
execute: 
  echo: true
  eval: true
  cache: false
---

## Load libraries
```{r}
#| message: false
#| warning: false

# Load required libraries
library(tidyverse)
library(viridis)
library(patchwork)
theme_set(theme_light())

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis",
  ggplot2.discrete.colour = function(...) scale_colour_viridis_d(...),
  ggplot2.discrete.fill = function(...) scale_fill_viridis_d(...)
)

# Set random seed for reproducibility
set.seed(123)
```

## Generate a fish population

I assume here that catches are a log-normal sample of the true fish population, and that it has a mean around 30 cm.

```{r}
# Generate a large population of fish
n_fish <- 100000

# Size ranges of the catch
min_length <- 6
max_length <- 90

# Parameters of the rlnorm
meanlog <- log(30)
sdlog <- 0.5

pop <- tibble(
  length = rlnorm(n_fish, meanlog = meanlog, sdlog = sdlog)) |>
  # Constrain to the range 5-90 cm
  filter(length >= min_length & length <= max_length) |> 
  rowid_to_column(var = "fish_id")

# Visualize the distribution with ggplot2
pop |>
  ggplot(aes(x = length)) +
  geom_histogram(bins = 30) +
  labs(title = "Length distribution of catch",
       x = "Length (cm)",
       y = "Count") +
  theme_minimal()
```

## Set up size classes and sampling scheme

I assume that the minimum size class for subsampling is 15 cm

```{r}
min_length_class <- 15

min(pop$length)

breaks = seq(min_length, max_length, by = 5)

# Assign length classes to the population
pop <- pop |> 
  mutate(length = round(length),
         bin = cut(length, breaks = breaks),
         bin_ext = bin) |> 
  mutate(length = length - 1) |> 
  mutate(bin_ext = case_when(
    length == 15 ~ fct_recode(bin_ext, "(16,21]" = "(11,16]"),
    TRUE ~ bin_ext
    )) |>
  drop_na(bin) |> 
  mutate(bin_ext = fct_recode(bin_ext, "[15,20)" = "(16,21]"))

pop |> 
  filter(length < 25) |> 
  distinct(length, bin) |> 
  ggplot(aes(as.factor(length), bin)) + 
  geom_point() + 
  theme(axis.text.x = element_text(angle = 90))

pop |> 
  filter(length < 25) |> 
  distinct(length, bin_ext) |> 
  ggplot(aes(as.factor(length), factor(bin_ext, levels = c("(6,11]", "(11,16]", "[15,20)", "(21,26]")))) +
  geom_point() +  
  labs(y = "bin") + 
  theme(axis.text.x = element_text(angle = 90))
```

## Sample 2 fish from each size bin and compare the size-distribution

```{r}
#| message: false
#| warning: false

d <- list()

nsim <- 5000

for(i in 1:nsim){
  
  dd <- pop |> 
    group_by(bin) |>
    filter(fish_id %in% sample(unique(fish_id), 2)) |> 
    ungroup() |> 
    mutate(iter = i)

  d[[i]] <- dd
  
}

df <- bind_rows(d)
```

We can plot the average number of fish per length class (when you sample 2 per 5 cm length class)

```{r}
df |> 
  summarise(n = n(), .by = c(bin, length)) |> 
  ggplot(aes(length, n/nsim, fill = bin)) +
  geom_bar(stat = "identity") + 
  labs(y = "Average sample size per length class")
```

Zoom in on the smaller size class

```{r}
df |> 
  filter(length >= 16 & length <= 25) |> 
  summarise(n = n(), .by = c(bin, length)) |> 
  ggplot(aes(as.factor(length), n/nsim, fill = bin)) +
  geom_bar(stat = "identity") + 
  labs(y = "Average sample size per length class")  
```

## What if we now extend the first size class?

```{r}
#| message: false
#| warning: false

d_ext <- list()
d <- NULL
dd <- NULL

for(i in 1:nsim){
  
  dd <- pop |> 
    group_by(bin_ext) |>
    filter(fish_id %in% sample(unique(fish_id), 2)) |> 
    ungroup() |> 
    mutate(iter = i)

  d[[i]] <- dd
  
}

df_ext <- bind_rows(d)
```

Combine and plot

```{r}
df2 <- bind_rows(
  df_ext |> mutate(scenario = "extended"),
  df |> mutate(scenario = "default"))

p1 <- df2 |> 
  filter(length >= 15 & length <= 20) |> 
  filter(!(length == 15 & scenario == "default")) |> 
  summarise(n = n(), .by = c(length, scenario)) |> 
  ggplot(aes(as.factor(length), n/nsim, fill = scenario)) +
  geom_bar(stat = "identity", position = "dodge") + 
  scale_fill_brewer(palette = "Set2") +
  theme(legend.position = "top") +
  labs(x = "length") +
  labs(y = "Average sample size per length class")

gain15 <- df2 |> 
  filter(length >= 15 & length <= 20) |> 
  filter(!(length == 15 & scenario == "default")) |> 
  summarise(n = n(), .by = c(length, scenario)) |> 
  pivot_wider(values_from = "n", names_from = "scenario") |> 
  filter(length == 15) |> pull(extended)

p2 <- df2 |> 
  filter(length >= 15 & length <= 20) |> 
  filter(!(length == 15 & scenario == "default")) |> 
  summarise(n = n(), .by = c(length, scenario)) |> 
  pivot_wider(values_from = "n", names_from = "scenario") |>
  mutate(diff = extended/nsim - default/nsim,
         diff = ifelse(length == 15, gain15/nsim, diff)) |> 
  ggplot(aes(as.factor(length), diff*100)) + 
  geom_bar(stat = "identity") +
  labs(x = "length") +
  scale_y_continuous(breaks = seq(-20, 40, by = 2))

(p1 / p2) + plot_layout(axes = "collect") 
```

## Conclusion
We get overall fewer fish per size group, but assuming a lognormal fish population the biggest change is in the bigger fish in the 15-20 size interval. Basically, samples per size goes down and which sizes go down most might be sensitive to assumptions about the population structure. Lastly, the average sample size across 1000 replicates is around 5--7 %.
